import os
import ssl
import logging
from celery import Celery
from kombu import Queue
from dotenv import load_dotenv

load_dotenv()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configuration Upstash
UPSTASH_REDIS_URL = os.environ.get("UPSTASH_REDIS_URL")
UPSTASH_REDIS_TOKEN = os.environ.get("UPSTASH_REDIS_TOKEN")

if not UPSTASH_REDIS_URL or not UPSTASH_REDIS_TOKEN:
    raise ValueError("Variables UPSTASH_REDIS_URL et UPSTASH_REDIS_TOKEN requises")

def build_upstash_url():
    """Construit l'URL Redis Upstash avec la m√©thode recommand√©e"""
    try:
        # M√©thode 1: URL compl√®te au format Upstash standard
        # Format recommand√© par Upstash: rediss://:password@endpoint:port
        
        # Nettoyer l'endpoint
        endpoint = UPSTASH_REDIS_URL.strip()
        
        # Supprimer les protocoles existants
        for protocol in ['rediss://', 'redis://', 'https://', 'http://']:
            if endpoint.startswith(protocol):
                endpoint = endpoint[len(protocol):]
        
        # Supprimer les credentials existants (format user:pass@)
        if '@' in endpoint:
            endpoint = endpoint.split('@')[-1]
        
        # Construire l'URL finale
        # Format Upstash: rediss://:token@host:port
        redis_url = f"rediss://:{UPSTASH_REDIS_TOKEN}@{endpoint}"
        
        # Ajouter le port si manquant
        if ':' not in endpoint:
            redis_url = f"rediss://:{UPSTASH_REDIS_TOKEN}@{endpoint}:6380"
        
        logger.info(f"‚úÖ URL Upstash construite: rediss://:***@{endpoint}")
        return redis_url
        
    except Exception as e:
        logger.error(f"‚ùå Erreur construction URL: {e}")
        # Fallback
        return f"rediss://:{UPSTASH_REDIS_TOKEN}@{UPSTASH_REDIS_URL}:6380"

# Construire l'URL
broker_url = build_upstash_url()

# Configuration Celery pour Upstash
celery_app = Celery('upstash_worker')

# Configuration sp√©cifique Upstash
celery_app.conf.update(
    # URLs
    broker_url=broker_url,
    result_backend=broker_url,
    
    # S√©rialisation
    task_serializer='json',
    result_serializer='json',
    accept_content=['json'],
    
    # Timezone
    timezone='Europe/Paris',
    enable_utc=True,
    
    # Configuration SSL pour Upstash (plus permissive)
    broker_use_ssl={
        'ssl_cert_reqs': ssl.CERT_NONE,
        'ssl_ca_certs': None,
        'ssl_certfile': None,
        'ssl_keyfile': None,
        'ssl_check_hostname': False,
        'ssl_ciphers': None,
    },
    
    # Configuration backend SSL
    redis_backend_use_ssl={
        'ssl_cert_reqs': ssl.CERT_NONE,
        'ssl_ca_certs': None,
        'ssl_certfile': None,
        'ssl_keyfile': None,
        'ssl_check_hostname': False,
    },
    
    # Param√®tres de connexion robustes pour Upstash
    broker_connection_retry_on_startup=True,
    broker_connection_retry=True,
    broker_connection_max_retries=50,  # Augment√©
    broker_connection_retry_delay=1.0,
    
    # Param√®tres Redis sp√©cifiques
    redis_max_connections=10,  # R√©duit pour Upstash
    redis_socket_timeout=30,   # Augment√©
    redis_socket_connect_timeout=30,  # Augment√©
    redis_retry_on_timeout=True,
    redis_health_check_interval=30,
    
    # Worker settings
    worker_prefetch_multiplier=1,
    task_acks_late=True,
    task_reject_on_worker_lost=True,
    
    # Timeouts
    task_soft_time_limit=300,
    task_time_limit=600,
    result_expires=3600,
    
    # Heartbeat (important pour Upstash)
    broker_heartbeat=None,  # D√©sactiver le heartbeat
    worker_disable_rate_limits=True,
    
    # Task routing
    task_default_queue='default',
    task_default_exchange='default',
    task_default_routing_key='default',
)

# Test de connexion am√©lior√©
def test_upstash_connection():
    """Test sp√©cifique pour Upstash Redis"""
    try:
        logger.info("üîç Test de connexion Upstash Redis...")
        
        # Test avec redis-py directement
        import redis
        
        # Parser l'URL pour extraire les composants
        url_parts = broker_url.replace('rediss://', '').replace('redis://', '')
        
        if '@' in url_parts:
            auth_part, host_part = url_parts.split('@', 1)
            password = auth_part.split(':', 1)[1] if ':' in auth_part else auth_part
        else:
            password = UPSTASH_REDIS_TOKEN
            host_part = url_parts
        
        if ':' in host_part:
            host, port = host_part.split(':', 1)
            port = int(port)
        else:
            host = host_part
            port = 6380
        
        # Connexion Redis directe
        r = redis.Redis(
            host=host,
            port=port,
            password=password,
            ssl=True,
            ssl_cert_reqs=ssl.CERT_NONE,
            ssl_check_hostname=False,
            socket_connect_timeout=10,
            socket_timeout=10,
            retry_on_timeout=True,
            health_check_interval=30,
            max_connections=5
        )
        
        # Test ping
        response = r.ping()
        logger.info(f"‚úÖ Ping Redis r√©ussi: {response}")
        
        # Test set/get
        r.set('test_key', 'test_value', ex=60)
        value = r.get('test_key')
        logger.info(f"‚úÖ Test set/get r√©ussi: {value}")
        
        # Test Celery
        from celery.backends.redis import RedisBackend
        backend = RedisBackend(app=celery_app, url=broker_url)
        backend.client.ping()
        logger.info("‚úÖ Backend Celery OK")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erreur test Upstash: {e}")
        logger.error(f"üîß Host: {host if 'host' in locals() else 'unknown'}")
        logger.error(f"üîß Port: {port if 'port' in locals() else 'unknown'}")
        return False

@celery_app.task(name="tasks.run_interview_analysis", bind=True)
def run_interview_analysis_task(self, conversation_history: list, job_description_text: list):
    """T√¢che d'analyse optimis√©e pour Upstash"""
    logger.info(f"üöÄ D√©marrage analyse Upstash - Task ID: {self.request.id}")
    
    try:
        import time
        
        # Progression avec √©tats plus courts pour √©viter les timeouts
        self.update_state(state='PROGRESS', meta={'current': 1, 'total': 3, 'status': 'D√©but analyse...'})
        time.sleep(1)
        
        # Analyse rapide
        sentiment = analyze_sentiment_quick(conversation_history)
        compatibility = analyze_compatibility_quick(conversation_history, job_description_text)
        
        self.update_state(state='PROGRESS', meta={'current': 2, 'total': 3, 'status': 'Calcul scores...'})
        time.sleep(1)
        
        # R√©sultat
        result = {
            "status": "completed",
            "task_id": self.request.id,
            "timestamp": time.time(),
            "analysis": {
                "sentiment_score": sentiment,
                "job_match_score": compatibility,
                "overall_score": round((sentiment + compatibility) / 2, 2),
                "conversation_length": len(conversation_history),
                "recommendations": generate_recommendations(sentiment, compatibility),
                "insights": [
                    f"Sentiment: {'Positif' if sentiment > 0.6 else 'Neutre' if sentiment > 0.4 else 'N√©gatif'}",
                    f"Compatibilit√©: {'√âlev√©e' if compatibility > 0.7 else 'Moyenne' if compatibility > 0.5 else 'Faible'}",
                    f"Recommandation: {'Poursuivre' if (sentiment + compatibility) / 2 > 0.6 else '√âvaluer davantage'}"
                ]
            }
        }
        
        self.update_state(state='PROGRESS', meta={'current': 3, 'total': 3, 'status': 'Termin√©'})
        
        logger.info(f"‚úÖ Analyse termin√©e - Score: {result['analysis']['overall_score']}")
        return result
        
    except Exception as e:
        error_msg = f"Erreur analyse: {str(e)}"
        logger.error(f"‚ùå {error_msg}")
        self.update_state(state='FAILURE', meta={'error': error_msg})
        raise

@celery_app.task(name="tasks.generate_report", bind=True)
def generate_report_task(self, analysis_data: dict):
    """G√©n√©ration de rapport optimis√©e"""
    logger.info(f"üìä G√©n√©ration rapport - Task ID: {self.request.id}")
    
    try:
        import time
        
        self.update_state(state='PROGRESS', meta={'current': 1, 'total': 2, 'status': 'G√©n√©ration...'})
        time.sleep(2)
        
        report = {
            "report_id": f"RPT_{int(time.time())}",
            "generated_at": time.time(),
            "task_id": self.request.id,
            "summary": "Rapport g√©n√©r√© avec succ√®s",
            "data": analysis_data,
            "status": "completed"
        }
        
        self.update_state(state='PROGRESS', meta={'current': 2, 'total': 2, 'status': 'Termin√©'})
        
        logger.info(f"‚úÖ Rapport g√©n√©r√©")
        return report
        
    except Exception as e:
        error_msg = f"Erreur rapport: {str(e)}"
        logger.error(f"‚ùå {error_msg}")
        self.update_state(state='FAILURE', meta={'error': error_msg})
        raise

# Fonctions d'analyse rapides
def analyze_sentiment_quick(conversation_history):
    """Analyse rapide du sentiment"""
    positive_words = ['motiv√©', 'excellent', 'bien', 'parfait', 'super']
    total_score = 0
    message_count = 0
    
    for msg in conversation_history:
        if msg.get("role") == "user":
            content = msg.get("content", "").lower()
            message_count += 1
            score = sum(1 for word in positive_words if word in content)
            total_score += min(score, 1)  # Max 1 par message
    
    return round(total_score / max(message_count, 1), 2)

def analyze_compatibility_quick(conversation_history, job_description_text):
    """Analyse rapide de compatibilit√©"""
    if not job_description_text:
        return 0.5
    
    job_words = set(job_description_text[0].lower().split())
    candidate_text = " ".join([msg.get("content", "") for msg in conversation_history if msg.get("role") == "user"]).lower()
    candidate_words = set(candidate_text.split())
    
    common = job_words & candidate_words
    important_common = [w for w in common if len(w) > 3]
    
    return round(min(0.9, len(important_common) / max(len(job_words) * 0.2, 1)), 2)

def generate_recommendations(sentiment, compatibility):
    """G√©n√®re des recommandations"""
    recommendations = []
    
    if sentiment > 0.7 and compatibility > 0.7:
        recommendations.append("üü¢ Candidat excellent - Recommand√© pour embauche")
    elif sentiment > 0.5 and compatibility > 0.5:
        recommendations.append("üü° Candidat prometteur - Entretien technique recommand√©")
    else:
        recommendations.append("üî¥ Candidat √† √©valuer davantage")
    
    if sentiment < 0.4:
        recommendations.append("‚ö†Ô∏è Travailler sur la motivation")
    if compatibility < 0.4:
        recommendations.append("üìö Formation n√©cessaire sur les comp√©tences requises")
    
    return recommendations

if __name__ == "__main__":
    logger.info("üîß Test configuration Upstash...")
    if test_upstash_connection():
        logger.info("üéâ Configuration Upstash OK - Worker pr√™t")
    else:
        logger.error("üí• Probl√®me configuration Upstash")
    
    logger.info("üöÄ D√©marrage: celery -A main worker --loglevel=info --concurrency=1")
